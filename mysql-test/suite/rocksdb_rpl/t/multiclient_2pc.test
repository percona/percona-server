--source include/not_group_replication_plugin.inc
--source include/have_rocksdb.inc
--source include/have_binlog_format_row.inc
--source include/have_debug.inc
--source include/have_debug_sync.inc
# The test involves a crash which does not seem to be handled well with
# mysql-test/lib/My/SafeProcess/my_safe_process under valgrind as it hangs
# forever. The test did not mean to verify the memory leaks so not much
# coverage should be missed by not running it under valgrind.
--source include/not_valgrind.inc

--let $search_file=$MYSQLTEST_VARDIR/tmp/rocksdb.multiclient_2pc.err
--let $restart_parameters=restart:--log-error=$search_file

# there is no need to track original global values as mysqld is restarted
# at the end of the test
set @@global.max_binlog_size = 4096;
create table t1 (a int primary key, b int, c varchar(255)) engine=rocksdb;

connect (con1, localhost, root,,);
connect (con2, localhost, root,,);

# On connection one we insert a row and pause after prepare marker is written to
# WAL. Connection two then inserts many rows to rotate the binlog. After
# connection two completes, connection one continues only to crash before commit
# but after binlog write. On crash recovery we see that connection one's value
# has been recovered and commited
connection con1;
--echo 'con1'
--exec echo "$restart_parameters" > $MYSQLTEST_VARDIR/tmp/mysqld.1.expect
set session debug="d,crash_commit_after_log";
set debug_sync='rocksdb.prepared SIGNAL parked WAIT_FOR go';
--error 0,CR_SERVER_LOST
--send insert into t1 values (1, 1, "iamtheogthealphaandomega");

connection con2;
--echo 'con2'
insert into t1 values (2, 1, "i_am_just_here_to_trigger_a_flush");

# Disable syncing for faster inserting of dummy rows
# These rows only purpose is to rotate the binlog
set @@global.rocksdb_flush_log_at_trx_commit = 0;
set @@global.sync_binlog = 0;

SET debug_sync='now WAIT_FOR parked';
--disable_query_log
--let $pk= 3
# binlog size is 4096 bytes so with that many insertion it will definitely rotate
while ($pk < 4096) {
  eval insert into t1 values ($pk, 1, "foobardatagoesheresothatmorelogsrollwhichiswhatwewant");
  --inc $pk
}
--enable_query_log

# re-enable syncing then write to trigger a flush
# before we trigger the crash to simulate full-durability
set @@global.rocksdb_flush_log_at_trx_commit = 2;
set @@global.sync_binlog = 1;

insert into t1 values (1000000, 1, "i_am_just_here_to_trigger_a_flush");

--error 0,CR_SERVER_LOST
set debug_sync='now SIGNAL go';

--source include/wait_until_disconnected.inc
--enable_reconnect
--source include/wait_until_connected_again.inc
--disable_reconnect

--exec python2 suite/rocksdb/t/check_log_for_xa.py $search_file commit,prepare,rollback

select * from t1 where a=1;
select count(*) from t1;

drop table t1;

# cleanup
--let $search_file=
--let $restart_parameters=
--source include/restart_mysqld.inc
--remove_file $MYSQLTEST_VARDIR/tmp/rocksdb.multiclient_2pc.err
